{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:37:21.951693600Z",
     "start_time": "2023-10-31T19:37:21.910743Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet34\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.reddit.com/r/MachineLearning/comments/kvs1ex/d_here_are_17_ways_of_making_pytorch_training/\n",
    "Tried some of the trick in this post for 1 epoch. ~17 seconds is with Cuda on my GPU (RTX 3070) \n",
    "Defining num_workers and pin_memory made the performance worse with resnet34, may be different with other models.\n",
    "Could also possibly be because of our dataset not being that large, these tricks might help for larger datasets.\n",
    "Same with \n",
    "```torch.backends.cudnn.benchmark = True```\n",
    "Increasing the batch_size to 128 sometimes increased the performance from ~17secs -> ~16 but not always"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc31c4e1201df0f8"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ebf5f1bdccc554fd"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "dataset = ImageFolder(\"./Colorectal Cancer\", transform=ToTensor())\n",
    "train_set, validation_set, test_set = torch.utils.data.random_split(dataset, [0.8, 0.1, 0.1])\n",
    "train_loader = DataLoader(train_set, shuffle=True, batch_size=64)\n",
    "validation_loader = DataLoader(validation_set, shuffle=True, batch_size=64)\n",
    "test_loader = DataLoader(test_set, shuffle=True, batch_size=64)\n",
    "print(\"Data loaded\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:37:21.970695300Z",
     "start_time": "2023-10-31T19:37:21.927693900Z"
    }
   },
   "id": "a6b79f74273a67e6"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "\n",
    "model = resnet34(num_classes=3).to(device)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(0)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.001)\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "num_epoch = 10"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:37:22.239548100Z",
     "start_time": "2023-10-31T19:37:21.957696400Z"
    }
   },
   "id": "c121facff5630284"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using Automatix Mixed Precision increase heavily the performance.\n",
    "From ~17 secs to ~13 secs in terms of performance."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f09b1f8c581a2fe0"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minibatch loss: 1.0968856811523438\n",
      "minibatch loss: 1.0917892456054688\n",
      "minibatch loss: 1.07843017578125\n",
      "minibatch loss: 1.1226272583007812\n",
      "minibatch loss: 1.2240753173828125\n",
      "minibatch loss: 1.1814818382263184\n",
      "minibatch loss: 1.1292850971221924\n",
      "minibatch loss: 1.0041580200195312\n",
      "minibatch loss: 0.9169168472290039\n",
      "minibatch loss: 0.9315519332885742\n",
      "minibatch loss: 0.9014134407043457\n",
      "minibatch loss: 0.8045858144760132\n",
      "minibatch loss: 0.9114318490028381\n",
      "minibatch loss: 0.884507417678833\n",
      "minibatch loss: 0.6950580477714539\n",
      "minibatch loss: 0.9178089499473572\n",
      "minibatch loss: 0.8630834221839905\n",
      "minibatch loss: 0.8506239652633667\n",
      "minibatch loss: 0.756601095199585\n",
      "minibatch loss: 0.8579224944114685\n",
      "minibatch loss: 0.7405933737754822\n",
      "minibatch loss: 0.8551340699195862\n",
      "minibatch loss: 0.6445809006690979\n",
      "minibatch loss: 0.4879162907600403\n",
      "minibatch loss: 0.6637753248214722\n",
      "minibatch loss: 1.525828242301941\n",
      "minibatch loss: 1.0996928215026855\n",
      "minibatch loss: 0.9228406548500061\n",
      "minibatch loss: 0.4315136671066284\n",
      "minibatch loss: 0.6908745765686035\n",
      "minibatch loss: 0.6904157400131226\n",
      "minibatch loss: 0.5860562324523926\n",
      "minibatch loss: 0.5503625869750977\n",
      "minibatch loss: 0.4381239116191864\n",
      "minibatch loss: 0.5810183882713318\n",
      "minibatch loss: 0.5419414043426514\n",
      "minibatch loss: 0.630925178527832\n",
      "minibatch loss: 0.6585975289344788\n",
      "minibatch loss: 0.5603457093238831\n",
      "minibatch loss: 0.34812793135643005\n",
      "minibatch loss: 0.41191336512565613\n",
      "minibatch loss: 0.43056774139404297\n",
      "minibatch loss: 0.5982671976089478\n",
      "minibatch loss: 0.46032676100730896\n",
      "minibatch loss: 0.5551915764808655\n",
      "minibatch loss: 0.4078061282634735\n",
      "minibatch loss: 0.4734684228897095\n",
      "minibatch loss: 0.5880413055419922\n",
      "minibatch loss: 0.6280122399330139\n",
      "minibatch loss: 0.5743926167488098\n",
      "minibatch loss: 0.5504363775253296\n",
      "minibatch loss: 0.3379720151424408\n",
      "minibatch loss: 0.5665605068206787\n",
      "minibatch loss: 0.2905285060405731\n",
      "minibatch loss: 0.40826910734176636\n",
      "minibatch loss: 0.45066964626312256\n",
      "minibatch loss: 0.4762802720069885\n",
      "minibatch loss: 0.3288496434688568\n",
      "minibatch loss: 0.4135601818561554\n",
      "minibatch loss: 0.3186125159263611\n",
      "minibatch loss: 0.47152167558670044\n",
      "minibatch loss: 0.3305237591266632\n",
      "minibatch loss: 0.32785728573799133\n",
      "minibatch loss: 0.44272902607917786\n",
      "minibatch loss: 0.5855973958969116\n",
      "minibatch loss: 0.4440078139305115\n",
      "minibatch loss: 0.5216481685638428\n",
      "minibatch loss: 0.5360101461410522\n",
      "minibatch loss: 0.3896072804927826\n",
      "minibatch loss: 0.3593580722808838\n",
      "minibatch loss: 0.718275785446167\n",
      "minibatch loss: 0.4542415738105774\n",
      "minibatch loss: 0.24973298609256744\n",
      "minibatch loss: 0.5452785491943359\n",
      "minibatch loss: 0.41410061717033386\n",
      "Epoch 0: last batch loss: 0.41410061717033386\n",
      "minibatch loss: 0.24614079296588898\n",
      "minibatch loss: 0.6888746023178101\n",
      "minibatch loss: 0.6118084192276001\n",
      "minibatch loss: 0.4227238595485687\n",
      "minibatch loss: 0.3266899883747101\n",
      "minibatch loss: 0.5589355826377869\n",
      "minibatch loss: 0.29905951023101807\n",
      "minibatch loss: 0.648591160774231\n",
      "minibatch loss: 0.31883856654167175\n",
      "minibatch loss: 0.45852774381637573\n",
      "minibatch loss: 0.4673648774623871\n",
      "minibatch loss: 1.0408686399459839\n",
      "minibatch loss: 0.5847717523574829\n",
      "minibatch loss: 0.5938119292259216\n",
      "minibatch loss: 0.5722779035568237\n",
      "minibatch loss: 0.5102882385253906\n",
      "minibatch loss: 0.3973062336444855\n",
      "minibatch loss: 0.32289984822273254\n",
      "minibatch loss: 0.492245614528656\n",
      "minibatch loss: 0.42564600706100464\n",
      "minibatch loss: 0.33037078380584717\n",
      "minibatch loss: 0.3052363097667694\n",
      "minibatch loss: 0.46012696623802185\n",
      "minibatch loss: 0.443378210067749\n",
      "minibatch loss: 0.3816457986831665\n",
      "minibatch loss: 0.3264683187007904\n",
      "minibatch loss: 0.3089635372161865\n",
      "minibatch loss: 0.3260544538497925\n",
      "minibatch loss: 0.2837579548358917\n",
      "minibatch loss: 0.2783263921737671\n",
      "minibatch loss: 0.3097091019153595\n",
      "minibatch loss: 0.4620617926120758\n",
      "minibatch loss: 0.34691134095191956\n",
      "minibatch loss: 0.2482147067785263\n",
      "minibatch loss: 0.36268848180770874\n",
      "minibatch loss: 0.4746192991733551\n",
      "minibatch loss: 0.5708856582641602\n",
      "minibatch loss: 0.36998867988586426\n",
      "minibatch loss: 0.3999662399291992\n",
      "minibatch loss: 0.54475998878479\n",
      "minibatch loss: 0.35625797510147095\n",
      "minibatch loss: 0.33898788690567017\n",
      "minibatch loss: 0.521824836730957\n",
      "minibatch loss: 0.546169638633728\n",
      "minibatch loss: 0.33906394243240356\n",
      "minibatch loss: 0.27974194288253784\n",
      "minibatch loss: 0.4104386270046234\n",
      "minibatch loss: 0.3950945734977722\n",
      "minibatch loss: 0.3177257180213928\n",
      "minibatch loss: 0.3474694490432739\n",
      "minibatch loss: 0.28078702092170715\n",
      "minibatch loss: 0.2786378264427185\n",
      "minibatch loss: 0.27058178186416626\n",
      "minibatch loss: 0.1872216761112213\n",
      "minibatch loss: 0.26740115880966187\n",
      "minibatch loss: 0.36184602975845337\n",
      "minibatch loss: 0.33783286809921265\n",
      "minibatch loss: 0.3573157787322998\n",
      "minibatch loss: 0.279942125082016\n",
      "minibatch loss: 0.39632365107536316\n",
      "minibatch loss: 0.2928854525089264\n",
      "minibatch loss: 0.2557032108306885\n",
      "minibatch loss: 0.1254759430885315\n",
      "minibatch loss: 0.2995622754096985\n",
      "minibatch loss: 0.4811517894268036\n",
      "minibatch loss: 0.2644844949245453\n",
      "minibatch loss: 0.2856186032295227\n",
      "minibatch loss: 0.3143402934074402\n",
      "minibatch loss: 0.23854345083236694\n",
      "minibatch loss: 0.3125872313976288\n",
      "minibatch loss: 0.41261976957321167\n",
      "minibatch loss: 0.23506124317646027\n",
      "minibatch loss: 0.1964644491672516\n",
      "minibatch loss: 0.12471496313810349\n",
      "minibatch loss: 0.5503227114677429\n",
      "Epoch 1: last batch loss: 0.5503227114677429\n",
      "minibatch loss: 0.23442645370960236\n",
      "minibatch loss: 0.3368949294090271\n",
      "minibatch loss: 0.2766435742378235\n",
      "minibatch loss: 0.33020853996276855\n",
      "minibatch loss: 0.1620829999446869\n",
      "minibatch loss: 0.37258103489875793\n",
      "minibatch loss: 0.4362775683403015\n",
      "minibatch loss: 0.3800898790359497\n",
      "minibatch loss: 0.21841742098331451\n",
      "minibatch loss: 0.1670355647802353\n",
      "minibatch loss: 0.1649756282567978\n",
      "minibatch loss: 0.366919606924057\n",
      "minibatch loss: 0.29647648334503174\n",
      "minibatch loss: 0.3547211289405823\n",
      "minibatch loss: 0.3150341212749481\n",
      "minibatch loss: 0.2000965029001236\n",
      "minibatch loss: 0.31205466389656067\n",
      "minibatch loss: 0.1759396195411682\n",
      "minibatch loss: 0.5398460030555725\n",
      "minibatch loss: 0.6311609148979187\n",
      "minibatch loss: 0.5611306428909302\n",
      "minibatch loss: 0.27664414048194885\n",
      "minibatch loss: 0.22674298286437988\n",
      "minibatch loss: 0.12732653319835663\n",
      "minibatch loss: 0.34775280952453613\n",
      "minibatch loss: 0.5850262641906738\n",
      "minibatch loss: 0.23214378952980042\n",
      "minibatch loss: 0.1634368896484375\n",
      "minibatch loss: 0.2691574692726135\n",
      "minibatch loss: 0.25050467252731323\n",
      "minibatch loss: 0.12119916081428528\n",
      "minibatch loss: 0.13801272213459015\n",
      "minibatch loss: 0.2745596766471863\n",
      "minibatch loss: 0.3151373267173767\n",
      "minibatch loss: 0.2705424427986145\n",
      "minibatch loss: 0.2139436900615692\n",
      "minibatch loss: 0.10342419892549515\n",
      "minibatch loss: 0.3711438775062561\n",
      "minibatch loss: 0.2742837965488434\n",
      "minibatch loss: 0.3124665319919586\n",
      "minibatch loss: 0.12818396091461182\n",
      "minibatch loss: 0.12368439137935638\n",
      "minibatch loss: 0.2517021894454956\n",
      "minibatch loss: 0.2551302909851074\n",
      "minibatch loss: 0.3338886499404907\n",
      "minibatch loss: 0.16026362776756287\n",
      "minibatch loss: 0.15523426234722137\n",
      "minibatch loss: 0.34016621112823486\n",
      "minibatch loss: 0.20111246407032013\n",
      "minibatch loss: 0.2570592761039734\n",
      "minibatch loss: 0.1706390678882599\n",
      "minibatch loss: 0.2565360963344574\n",
      "minibatch loss: 0.37614697217941284\n",
      "minibatch loss: 0.5254350900650024\n",
      "minibatch loss: 0.3832574188709259\n",
      "minibatch loss: 0.08372046053409576\n",
      "minibatch loss: 0.33434373140335083\n",
      "minibatch loss: 0.18693742156028748\n",
      "minibatch loss: 0.2618269622325897\n",
      "minibatch loss: 0.19359003007411957\n",
      "minibatch loss: 0.19339339435100555\n",
      "minibatch loss: 0.26435309648513794\n",
      "minibatch loss: 0.34617820382118225\n",
      "minibatch loss: 0.18495099246501923\n",
      "minibatch loss: 0.27155938744544983\n",
      "minibatch loss: 0.20279312133789062\n",
      "minibatch loss: 0.3990400731563568\n",
      "minibatch loss: 0.2622297406196594\n",
      "minibatch loss: 0.21675729751586914\n",
      "minibatch loss: 0.3720654547214508\n",
      "minibatch loss: 0.44066545367240906\n",
      "minibatch loss: 0.23714497685432434\n",
      "minibatch loss: 0.2639049291610718\n",
      "minibatch loss: 0.2329200655221939\n",
      "minibatch loss: 0.10734610259532928\n",
      "Epoch 2: last batch loss: 0.10734610259532928\n",
      "minibatch loss: 0.2652800679206848\n",
      "minibatch loss: 0.1141778826713562\n",
      "minibatch loss: 0.16432932019233704\n",
      "minibatch loss: 0.11879436671733856\n",
      "minibatch loss: 0.7357310652732849\n",
      "minibatch loss: 0.1253860890865326\n",
      "minibatch loss: 0.2737688720226288\n",
      "minibatch loss: 0.1810382455587387\n",
      "minibatch loss: 0.15572795271873474\n",
      "minibatch loss: 0.16278457641601562\n",
      "minibatch loss: 0.25093215703964233\n",
      "minibatch loss: 0.16189217567443848\n",
      "minibatch loss: 0.14859333634376526\n",
      "minibatch loss: 0.12374777346849442\n",
      "minibatch loss: 0.16399255394935608\n",
      "minibatch loss: 0.5201259255409241\n",
      "minibatch loss: 0.2709566354751587\n",
      "minibatch loss: 0.1317230463027954\n",
      "minibatch loss: 0.17396394908428192\n",
      "minibatch loss: 0.22519078850746155\n",
      "minibatch loss: 0.16508755087852478\n",
      "minibatch loss: 0.2843390703201294\n",
      "minibatch loss: 0.4511042833328247\n",
      "minibatch loss: 0.381818026304245\n",
      "minibatch loss: 0.3582548499107361\n",
      "minibatch loss: 0.24365435540676117\n",
      "minibatch loss: 0.09905469417572021\n",
      "minibatch loss: 0.14516565203666687\n",
      "minibatch loss: 0.26440557837486267\n",
      "minibatch loss: 0.28965944051742554\n",
      "minibatch loss: 0.30315694212913513\n",
      "minibatch loss: 0.17363154888153076\n",
      "minibatch loss: 0.1866506189107895\n",
      "minibatch loss: 0.22486339509487152\n",
      "minibatch loss: 0.3929918706417084\n",
      "minibatch loss: 0.22783547639846802\n",
      "minibatch loss: 0.08452369272708893\n",
      "minibatch loss: 0.1375640332698822\n",
      "minibatch loss: 0.0798584520816803\n",
      "minibatch loss: 0.17782174050807953\n",
      "minibatch loss: 0.20791341364383698\n",
      "minibatch loss: 0.11805702745914459\n",
      "minibatch loss: 0.4350751042366028\n",
      "minibatch loss: 0.07186160981655121\n",
      "minibatch loss: 0.3057892322540283\n",
      "minibatch loss: 0.17389845848083496\n",
      "minibatch loss: 0.15423858165740967\n",
      "minibatch loss: 0.17210648953914642\n",
      "minibatch loss: 0.34162020683288574\n",
      "minibatch loss: 0.21546760201454163\n",
      "minibatch loss: 0.25152939558029175\n",
      "minibatch loss: 0.10698066651821136\n",
      "minibatch loss: 0.1650475114583969\n",
      "minibatch loss: 0.3296295404434204\n",
      "minibatch loss: 0.1646062731742859\n",
      "minibatch loss: 0.1574370414018631\n",
      "minibatch loss: 0.22894087433815002\n",
      "minibatch loss: 0.22806937992572784\n",
      "minibatch loss: 0.18938544392585754\n",
      "minibatch loss: 0.14682400226593018\n",
      "minibatch loss: 0.1127302274107933\n",
      "minibatch loss: 0.12503036856651306\n",
      "minibatch loss: 0.3098483383655548\n",
      "minibatch loss: 0.3127530515193939\n",
      "minibatch loss: 0.5279459953308105\n",
      "minibatch loss: 0.2924012243747711\n",
      "minibatch loss: 0.13055205345153809\n",
      "minibatch loss: 0.13199210166931152\n",
      "minibatch loss: 0.45192664861679077\n",
      "minibatch loss: 0.3782215416431427\n",
      "minibatch loss: 0.32876700162887573\n",
      "minibatch loss: 0.18983811140060425\n",
      "minibatch loss: 0.15471431612968445\n",
      "minibatch loss: 0.27987414598464966\n",
      "minibatch loss: 0.2406328022480011\n",
      "Epoch 3: last batch loss: 0.2406328022480011\n",
      "minibatch loss: 0.17507922649383545\n",
      "minibatch loss: 0.3056347072124481\n",
      "minibatch loss: 0.19393649697303772\n",
      "minibatch loss: 0.17985287308692932\n",
      "minibatch loss: 0.17911987006664276\n",
      "minibatch loss: 0.3417067527770996\n",
      "minibatch loss: 0.26578566431999207\n",
      "minibatch loss: 0.49635210633277893\n",
      "minibatch loss: 0.2878469228744507\n",
      "minibatch loss: 0.17870837450027466\n",
      "minibatch loss: 0.31958264112472534\n",
      "minibatch loss: 0.09949149191379547\n",
      "minibatch loss: 0.23736880719661713\n",
      "minibatch loss: 0.1552143543958664\n",
      "minibatch loss: 0.15580682456493378\n",
      "minibatch loss: 0.26386022567749023\n",
      "minibatch loss: 0.20864489674568176\n",
      "minibatch loss: 0.07208703458309174\n",
      "minibatch loss: 0.11565300822257996\n",
      "minibatch loss: 0.2813045382499695\n",
      "minibatch loss: 0.15251773595809937\n",
      "minibatch loss: 0.30768686532974243\n",
      "minibatch loss: 0.12667369842529297\n",
      "minibatch loss: 0.19529150426387787\n",
      "minibatch loss: 0.28054293990135193\n",
      "minibatch loss: 0.29148975014686584\n",
      "minibatch loss: 0.13336089253425598\n",
      "minibatch loss: 0.1752304881811142\n",
      "minibatch loss: 0.15897437930107117\n",
      "minibatch loss: 0.2198513001203537\n",
      "minibatch loss: 0.11196281760931015\n",
      "minibatch loss: 0.17616066336631775\n",
      "minibatch loss: 0.18464189767837524\n",
      "minibatch loss: 0.20376543700695038\n",
      "minibatch loss: 0.11315050721168518\n",
      "minibatch loss: 0.24481257796287537\n",
      "minibatch loss: 0.11700113117694855\n",
      "minibatch loss: 0.2667011022567749\n",
      "minibatch loss: 0.16093209385871887\n",
      "minibatch loss: 0.12687337398529053\n",
      "minibatch loss: 0.03628431260585785\n",
      "minibatch loss: 0.15605413913726807\n",
      "minibatch loss: 0.40487703680992126\n",
      "minibatch loss: 0.24961048364639282\n",
      "minibatch loss: 0.2402563840150833\n",
      "minibatch loss: 0.1308571696281433\n",
      "minibatch loss: 0.1549219787120819\n",
      "minibatch loss: 0.38973045349121094\n",
      "minibatch loss: 0.22101636230945587\n",
      "minibatch loss: 0.16717205941677094\n",
      "minibatch loss: 0.18589149415493011\n",
      "minibatch loss: 0.05296348035335541\n",
      "minibatch loss: 0.10567870736122131\n",
      "minibatch loss: 0.16079171001911163\n",
      "minibatch loss: 0.17838987708091736\n",
      "minibatch loss: 0.062231793999671936\n",
      "minibatch loss: 0.18883708119392395\n",
      "minibatch loss: 0.08619996905326843\n",
      "minibatch loss: 0.1353520303964615\n",
      "minibatch loss: 0.14160333573818207\n",
      "minibatch loss: 0.1272524744272232\n",
      "minibatch loss: 0.4323132634162903\n",
      "minibatch loss: 0.15505877137184143\n",
      "minibatch loss: 0.10054343938827515\n",
      "minibatch loss: 0.21810191869735718\n",
      "minibatch loss: 0.170007586479187\n",
      "minibatch loss: 0.08990605920553207\n",
      "minibatch loss: 0.2504003345966339\n",
      "minibatch loss: 0.07619960606098175\n",
      "minibatch loss: 0.10949711501598358\n",
      "minibatch loss: 0.11870516091585159\n",
      "minibatch loss: 0.18140503764152527\n",
      "minibatch loss: 0.33346280455589294\n",
      "minibatch loss: 0.13009323179721832\n",
      "minibatch loss: 0.16189071536064148\n",
      "Epoch 4: last batch loss: 0.16189071536064148\n",
      "minibatch loss: 0.14410287141799927\n",
      "minibatch loss: 0.15061607956886292\n",
      "minibatch loss: 0.07803761214017868\n",
      "minibatch loss: 0.3747270107269287\n",
      "minibatch loss: 0.14715497195720673\n",
      "minibatch loss: 0.23047718405723572\n",
      "minibatch loss: 0.2271394282579422\n",
      "minibatch loss: 0.18835893273353577\n",
      "minibatch loss: 0.21231451630592346\n",
      "minibatch loss: 0.2933111786842346\n",
      "minibatch loss: 0.22432145476341248\n",
      "minibatch loss: 0.14653390645980835\n",
      "minibatch loss: 0.23456443846225739\n",
      "minibatch loss: 0.26093506813049316\n",
      "minibatch loss: 0.3245559632778168\n",
      "minibatch loss: 0.2265321910381317\n",
      "minibatch loss: 0.38357964158058167\n",
      "minibatch loss: 0.26250705122947693\n",
      "minibatch loss: 0.15389035642147064\n",
      "minibatch loss: 0.27487584948539734\n",
      "minibatch loss: 0.15860754251480103\n",
      "minibatch loss: 0.1848737746477127\n",
      "minibatch loss: 0.11149627715349197\n",
      "minibatch loss: 0.11894611269235611\n",
      "minibatch loss: 0.20223739743232727\n",
      "minibatch loss: 0.11141995340585709\n",
      "minibatch loss: 0.2283240258693695\n",
      "minibatch loss: 0.08006074279546738\n",
      "minibatch loss: 0.14681608974933624\n",
      "minibatch loss: 0.08995538204908371\n",
      "minibatch loss: 0.11917059868574142\n",
      "minibatch loss: 0.19317488372325897\n",
      "minibatch loss: 0.1281697154045105\n",
      "minibatch loss: 0.12683087587356567\n",
      "minibatch loss: 0.11563500761985779\n",
      "minibatch loss: 0.1647649109363556\n",
      "minibatch loss: 0.20507004857063293\n",
      "minibatch loss: 0.0757681131362915\n",
      "minibatch loss: 0.077775739133358\n",
      "minibatch loss: 0.1105058342218399\n",
      "minibatch loss: 0.08761106431484222\n",
      "minibatch loss: 0.2129603624343872\n",
      "minibatch loss: 0.08026700466871262\n",
      "minibatch loss: 0.10706266015768051\n",
      "minibatch loss: 0.11195418238639832\n",
      "minibatch loss: 0.25417593121528625\n",
      "minibatch loss: 0.10044901072978973\n",
      "minibatch loss: 0.05593680590391159\n",
      "minibatch loss: 0.03584577888250351\n",
      "minibatch loss: 0.05120593309402466\n",
      "minibatch loss: 0.1278444528579712\n",
      "minibatch loss: 0.279258131980896\n",
      "minibatch loss: 0.08964069187641144\n",
      "minibatch loss: 0.1552492082118988\n",
      "minibatch loss: 0.1002853661775589\n",
      "minibatch loss: 0.08817434310913086\n",
      "minibatch loss: 0.16740205883979797\n",
      "minibatch loss: 0.5676356554031372\n",
      "minibatch loss: 0.14706793427467346\n",
      "minibatch loss: 0.18296343088150024\n",
      "minibatch loss: 0.16105428338050842\n",
      "minibatch loss: 0.14283861219882965\n",
      "minibatch loss: 0.06353173404932022\n",
      "minibatch loss: 0.09240931272506714\n",
      "minibatch loss: 0.04827641695737839\n",
      "minibatch loss: 0.13192029297351837\n",
      "minibatch loss: 0.16043692827224731\n",
      "minibatch loss: 0.14662578701972961\n",
      "minibatch loss: 0.057160958647727966\n",
      "minibatch loss: 0.05466177314519882\n",
      "minibatch loss: 0.053948935121297836\n",
      "minibatch loss: 0.09409292042255402\n",
      "minibatch loss: 0.03156723082065582\n",
      "minibatch loss: 0.08246229588985443\n",
      "minibatch loss: 0.10176358371973038\n",
      "Epoch 5: last batch loss: 0.10176358371973038\n",
      "minibatch loss: 0.04934075102210045\n",
      "minibatch loss: 0.12748490273952484\n",
      "minibatch loss: 0.07542690634727478\n",
      "minibatch loss: 0.11619718372821808\n",
      "minibatch loss: 0.0435696542263031\n",
      "minibatch loss: 0.1405852735042572\n",
      "minibatch loss: 0.08001945167779922\n",
      "minibatch loss: 0.14751455187797546\n",
      "minibatch loss: 0.11380037665367126\n",
      "minibatch loss: 0.08848284929990768\n",
      "minibatch loss: 0.12403953075408936\n",
      "minibatch loss: 0.2749871611595154\n",
      "minibatch loss: 0.14742928743362427\n",
      "minibatch loss: 0.15981525182724\n",
      "minibatch loss: 0.23507782816886902\n",
      "minibatch loss: 0.05040488764643669\n",
      "minibatch loss: 0.09048338979482651\n",
      "minibatch loss: 0.08608001470565796\n",
      "minibatch loss: 0.091187983751297\n",
      "minibatch loss: 0.1375068873167038\n",
      "minibatch loss: 0.12603995203971863\n",
      "minibatch loss: 0.1881714165210724\n",
      "minibatch loss: 0.19737257063388824\n",
      "minibatch loss: 0.1282871663570404\n",
      "minibatch loss: 0.03756501525640488\n",
      "minibatch loss: 0.1844490021467209\n",
      "minibatch loss: 0.33900249004364014\n",
      "minibatch loss: 0.09598711878061295\n",
      "minibatch loss: 0.21450269222259521\n",
      "minibatch loss: 0.11345931887626648\n",
      "minibatch loss: 0.04628966003656387\n",
      "minibatch loss: 0.24498894810676575\n",
      "minibatch loss: 0.06423932313919067\n",
      "minibatch loss: 0.20347905158996582\n",
      "minibatch loss: 0.21325381100177765\n",
      "minibatch loss: 0.22344252467155457\n",
      "minibatch loss: 0.12004578858613968\n",
      "minibatch loss: 0.2557855248451233\n",
      "minibatch loss: 0.19609956443309784\n",
      "minibatch loss: 0.10634172707796097\n",
      "minibatch loss: 0.08448861539363861\n",
      "minibatch loss: 0.19361095130443573\n",
      "minibatch loss: 0.07586848735809326\n",
      "minibatch loss: 0.14395402371883392\n",
      "minibatch loss: 0.03699074685573578\n",
      "minibatch loss: 0.06177295371890068\n",
      "minibatch loss: 0.06523045897483826\n",
      "minibatch loss: 0.16516301035881042\n",
      "minibatch loss: 0.3109263479709625\n",
      "minibatch loss: 0.20044411718845367\n",
      "minibatch loss: 0.24410749971866608\n",
      "minibatch loss: 0.19043567776679993\n",
      "minibatch loss: 0.18208234012126923\n",
      "minibatch loss: 0.10443149507045746\n",
      "minibatch loss: 0.06366837024688721\n",
      "minibatch loss: 0.14349956810474396\n",
      "minibatch loss: 0.12676504254341125\n",
      "minibatch loss: 0.17476384341716766\n",
      "minibatch loss: 0.1556835025548935\n",
      "minibatch loss: 0.31333231925964355\n",
      "minibatch loss: 0.1872166246175766\n",
      "minibatch loss: 0.1602683663368225\n",
      "minibatch loss: 0.13375326991081238\n",
      "minibatch loss: 0.053373001515865326\n",
      "minibatch loss: 0.24464930593967438\n",
      "minibatch loss: 0.12307648360729218\n",
      "minibatch loss: 0.1372251808643341\n",
      "minibatch loss: 0.06764809787273407\n",
      "minibatch loss: 0.08233033120632172\n",
      "minibatch loss: 0.10315118730068207\n",
      "minibatch loss: 0.10303901880979538\n",
      "minibatch loss: 0.14804914593696594\n",
      "minibatch loss: 0.3689645528793335\n",
      "minibatch loss: 0.09443795680999756\n",
      "minibatch loss: 0.09900481253862381\n",
      "Epoch 6: last batch loss: 0.09900481253862381\n",
      "minibatch loss: 0.09722460806369781\n",
      "minibatch loss: 0.12582682073116302\n",
      "minibatch loss: 0.06994393467903137\n",
      "minibatch loss: 0.10750284045934677\n",
      "minibatch loss: 0.038115642964839935\n",
      "minibatch loss: 0.1877487748861313\n",
      "minibatch loss: 0.1985979974269867\n",
      "minibatch loss: 0.24065664410591125\n",
      "minibatch loss: 0.17194850742816925\n",
      "minibatch loss: 0.06688018143177032\n",
      "minibatch loss: 0.039756447076797485\n",
      "minibatch loss: 0.15683040022850037\n",
      "minibatch loss: 0.20605574548244476\n",
      "minibatch loss: 0.08595219999551773\n",
      "minibatch loss: 0.07678422331809998\n",
      "minibatch loss: 0.07744386792182922\n",
      "minibatch loss: 0.21331749856472015\n",
      "minibatch loss: 0.14079691469669342\n",
      "minibatch loss: 0.0736408680677414\n",
      "minibatch loss: 0.19101104140281677\n",
      "minibatch loss: 0.0956377238035202\n",
      "minibatch loss: 0.07416363060474396\n",
      "minibatch loss: 0.16735807061195374\n",
      "minibatch loss: 0.22281548380851746\n",
      "minibatch loss: 0.29163065552711487\n",
      "minibatch loss: 0.07227987051010132\n",
      "minibatch loss: 0.08712734282016754\n",
      "minibatch loss: 0.1435122787952423\n",
      "minibatch loss: 0.09660026431083679\n",
      "minibatch loss: 0.04586773365736008\n",
      "minibatch loss: 0.09649109840393066\n",
      "minibatch loss: 0.0742071196436882\n",
      "minibatch loss: 0.08534178882837296\n",
      "minibatch loss: 0.10463634133338928\n",
      "minibatch loss: 0.08003639429807663\n",
      "minibatch loss: 0.11698349565267563\n",
      "minibatch loss: 0.31398510932922363\n",
      "minibatch loss: 0.07323339581489563\n",
      "minibatch loss: 0.09787863492965698\n",
      "minibatch loss: 0.12242086976766586\n",
      "minibatch loss: 0.04435812681913376\n",
      "minibatch loss: 0.06683968752622604\n",
      "minibatch loss: 0.05419524013996124\n",
      "minibatch loss: 0.049226921051740646\n",
      "minibatch loss: 0.10831627249717712\n",
      "minibatch loss: 0.05798658728599548\n",
      "minibatch loss: 0.23221245408058167\n",
      "minibatch loss: 0.038292042911052704\n",
      "minibatch loss: 0.06051842123270035\n",
      "minibatch loss: 0.05573838949203491\n",
      "minibatch loss: 0.21904751658439636\n",
      "minibatch loss: 0.046345923095941544\n",
      "minibatch loss: 0.058916542679071426\n",
      "minibatch loss: 0.025605695322155952\n",
      "minibatch loss: 0.1696159988641739\n",
      "minibatch loss: 0.08916594088077545\n",
      "minibatch loss: 0.13773688673973083\n",
      "minibatch loss: 0.11510197818279266\n",
      "minibatch loss: 0.03060709498822689\n",
      "minibatch loss: 0.09604401141405106\n",
      "minibatch loss: 0.19607917964458466\n",
      "minibatch loss: 0.1637985110282898\n",
      "minibatch loss: 0.10536692291498184\n",
      "minibatch loss: 0.11724106222391129\n",
      "minibatch loss: 0.019521117210388184\n",
      "minibatch loss: 0.051706597208976746\n",
      "minibatch loss: 0.13301542401313782\n",
      "minibatch loss: 0.08540976047515869\n",
      "minibatch loss: 0.16241757571697235\n",
      "minibatch loss: 0.07474350929260254\n",
      "minibatch loss: 0.1390618532896042\n",
      "minibatch loss: 0.09068327397108078\n",
      "minibatch loss: 0.17896972596645355\n",
      "minibatch loss: 0.13433900475502014\n",
      "minibatch loss: 0.0862618163228035\n",
      "Epoch 7: last batch loss: 0.0862618163228035\n",
      "minibatch loss: 0.03942067176103592\n",
      "minibatch loss: 0.10272182524204254\n",
      "minibatch loss: 0.03053470142185688\n",
      "minibatch loss: 0.17468899488449097\n",
      "minibatch loss: 0.057799916714429855\n",
      "minibatch loss: 0.12684093415737152\n",
      "minibatch loss: 0.016001703217625618\n",
      "minibatch loss: 0.14795100688934326\n",
      "minibatch loss: 0.08578267693519592\n",
      "minibatch loss: 0.08311399817466736\n",
      "minibatch loss: 0.09178198873996735\n",
      "minibatch loss: 0.0807034969329834\n",
      "minibatch loss: 0.063717320561409\n",
      "minibatch loss: 0.16209562122821808\n",
      "minibatch loss: 0.18758203089237213\n",
      "minibatch loss: 0.13743604719638824\n",
      "minibatch loss: 0.04362623766064644\n",
      "minibatch loss: 0.04217110946774483\n",
      "minibatch loss: 0.061298668384552\n",
      "minibatch loss: 0.06719134002923965\n",
      "minibatch loss: 0.11613757163286209\n",
      "minibatch loss: 0.19835449755191803\n",
      "minibatch loss: 0.06071324273943901\n",
      "minibatch loss: 0.020082440227270126\n",
      "minibatch loss: 0.0309453122317791\n",
      "minibatch loss: 0.030155939981341362\n",
      "minibatch loss: 0.06227525696158409\n",
      "minibatch loss: 0.03397013992071152\n",
      "minibatch loss: 0.06590284407138824\n",
      "minibatch loss: 0.08261023461818695\n",
      "minibatch loss: 0.04677335172891617\n",
      "minibatch loss: 0.058199528604745865\n",
      "minibatch loss: 0.09053965657949448\n",
      "minibatch loss: 0.06600826978683472\n",
      "minibatch loss: 0.04270254820585251\n",
      "minibatch loss: 0.05666070803999901\n",
      "minibatch loss: 0.11681206524372101\n",
      "minibatch loss: 0.11624781042337418\n",
      "minibatch loss: 0.14077900350093842\n",
      "minibatch loss: 0.04675544425845146\n",
      "minibatch loss: 0.013954177498817444\n",
      "minibatch loss: 0.1365983784198761\n",
      "minibatch loss: 0.08846213668584824\n",
      "minibatch loss: 0.21240384876728058\n",
      "minibatch loss: 0.08587227761745453\n",
      "minibatch loss: 0.030248533934354782\n",
      "minibatch loss: 0.01686878874897957\n",
      "minibatch loss: 0.2304004728794098\n",
      "minibatch loss: 0.1963634490966797\n",
      "minibatch loss: 0.09333944320678711\n",
      "minibatch loss: 0.03810124844312668\n",
      "minibatch loss: 0.04506184905767441\n",
      "minibatch loss: 0.2131163328886032\n",
      "minibatch loss: 0.119749054312706\n",
      "minibatch loss: 0.02986224740743637\n",
      "minibatch loss: 0.14773231744766235\n",
      "minibatch loss: 0.05930988863110542\n",
      "minibatch loss: 0.08313073217868805\n",
      "minibatch loss: 0.0781119242310524\n",
      "minibatch loss: 0.344722718000412\n",
      "minibatch loss: 0.0746646597981453\n",
      "minibatch loss: 0.03392912447452545\n",
      "minibatch loss: 0.11287282407283783\n",
      "minibatch loss: 0.23583900928497314\n",
      "minibatch loss: 0.060750141739845276\n",
      "minibatch loss: 0.047711603343486786\n",
      "minibatch loss: 0.073263980448246\n",
      "minibatch loss: 0.04747125506401062\n",
      "minibatch loss: 0.0730658769607544\n",
      "minibatch loss: 0.10822402685880661\n",
      "minibatch loss: 0.055979423224925995\n",
      "minibatch loss: 0.14444321393966675\n",
      "minibatch loss: 0.045348815619945526\n",
      "minibatch loss: 0.21229223906993866\n",
      "minibatch loss: 0.1777341514825821\n",
      "Epoch 8: last batch loss: 0.1777341514825821\n",
      "minibatch loss: 0.06782584637403488\n",
      "minibatch loss: 0.05098166689276695\n",
      "minibatch loss: 0.038450103253126144\n",
      "minibatch loss: 0.049610037356615067\n",
      "minibatch loss: 0.12132647633552551\n",
      "minibatch loss: 0.03411846607923508\n",
      "minibatch loss: 0.09757072478532791\n",
      "minibatch loss: 0.19085156917572021\n",
      "minibatch loss: 0.16525089740753174\n",
      "minibatch loss: 0.05724523589015007\n",
      "minibatch loss: 0.0372588112950325\n",
      "minibatch loss: 0.09112947434186935\n",
      "minibatch loss: 0.05107146501541138\n",
      "minibatch loss: 0.021963292732834816\n",
      "minibatch loss: 0.05738171935081482\n",
      "minibatch loss: 0.06126387417316437\n",
      "minibatch loss: 0.24494385719299316\n",
      "minibatch loss: 0.028131559491157532\n",
      "minibatch loss: 0.07557252794504166\n",
      "minibatch loss: 0.0605149045586586\n",
      "minibatch loss: 0.1346825361251831\n",
      "minibatch loss: 0.049929480999708176\n",
      "minibatch loss: 0.03460933640599251\n",
      "minibatch loss: 0.027959274128079414\n",
      "minibatch loss: 0.05292702093720436\n",
      "minibatch loss: 0.048873160034418106\n",
      "minibatch loss: 0.06523717939853668\n",
      "minibatch loss: 0.07913407683372498\n",
      "minibatch loss: 0.06013193354010582\n",
      "minibatch loss: 0.09861143678426743\n",
      "minibatch loss: 0.11406851559877396\n",
      "minibatch loss: 0.06822545826435089\n",
      "minibatch loss: 0.1366824358701706\n",
      "minibatch loss: 0.044122666120529175\n",
      "minibatch loss: 0.04272701218724251\n",
      "minibatch loss: 0.03132873773574829\n",
      "minibatch loss: 0.09368543326854706\n",
      "minibatch loss: 0.06286218762397766\n",
      "minibatch loss: 0.024932045489549637\n",
      "minibatch loss: 0.12165026366710663\n",
      "minibatch loss: 0.1670956015586853\n",
      "minibatch loss: 0.07147932052612305\n",
      "minibatch loss: 0.0057412609457969666\n",
      "minibatch loss: 0.17367558181285858\n",
      "minibatch loss: 0.1708301305770874\n",
      "minibatch loss: 0.08125040680170059\n",
      "minibatch loss: 0.07236350327730179\n",
      "minibatch loss: 0.017819371074438095\n",
      "minibatch loss: 0.0423736572265625\n",
      "minibatch loss: 0.11847266554832458\n",
      "minibatch loss: 0.016312213614583015\n",
      "minibatch loss: 0.016618359833955765\n",
      "minibatch loss: 0.2118092030286789\n",
      "minibatch loss: 0.021858125925064087\n",
      "minibatch loss: 0.053871043026447296\n",
      "minibatch loss: 0.05995844304561615\n",
      "minibatch loss: 0.12110405415296555\n",
      "minibatch loss: 0.13388827443122864\n",
      "minibatch loss: 0.04028651863336563\n",
      "minibatch loss: 0.16380691528320312\n",
      "minibatch loss: 0.11877331137657166\n",
      "minibatch loss: 0.20529887080192566\n",
      "minibatch loss: 0.05052892491221428\n",
      "minibatch loss: 0.07353523373603821\n",
      "minibatch loss: 0.10731145739555359\n",
      "minibatch loss: 0.05347007140517235\n",
      "minibatch loss: 0.05896664410829544\n",
      "minibatch loss: 0.1882983148097992\n",
      "minibatch loss: 0.16626687347888947\n",
      "minibatch loss: 0.1008111834526062\n",
      "minibatch loss: 0.04554873704910278\n",
      "minibatch loss: 0.11967180669307709\n",
      "minibatch loss: 0.10849840939044952\n",
      "minibatch loss: 0.19439896941184998\n",
      "minibatch loss: 0.270704984664917\n",
      "Epoch 9: last batch loss: 0.270704984664917\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(num_epoch):\n",
    "    \n",
    "    # Pass an epoch over the training data in batch_size chunks\n",
    "    for features, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # TODO:: Check if this changes \n",
    "        with torch.cuda.amp.autocast():\n",
    "            y_pred = model(features)\n",
    "            l = loss(y_pred ,labels)\n",
    "\n",
    "        scaler.scale(l).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # # # forward\n",
    "        # y_pred = model(features)\n",
    "        # l = loss(y_pred, labels)\n",
    "        # model.zero_grad()\n",
    "        # # backprop and step\n",
    "        # l.backward()\n",
    "        # optimizer.step()\n",
    "        print(f\"minibatch loss: {l}\")\n",
    "    print(f\"Epoch {epoch}: last batch loss: {l}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:39:28.417941900Z",
     "start_time": "2023-10-31T19:37:22.241547900Z"
    }
   },
   "id": "2ae2be57003fcc8e"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:39:28.442943300Z",
     "start_time": "2023-10-31T19:39:28.419942Z"
    }
   },
   "id": "6c6f0915206b5a3e"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-31T19:39:28.449942700Z",
     "start_time": "2023-10-31T19:39:28.436943100Z"
    }
   },
   "id": "b95a685f2e1ad660"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
